{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-21T08:02:05.400474Z",
     "start_time": "2025-05-21T08:02:05.203779Z"
    }
   },
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "print(sys.version_info)\n",
    "for module in mpl, np, pd, sklearn, torch:\n",
    "    print(module.__name__, module.__version__)\n",
    "\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(device)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys.version_info(major=3, minor=12, micro=3, releaselevel='final', serial=0)\n",
      "matplotlib 3.10.1\n",
      "numpy 2.2.4\n",
      "pandas 2.2.3\n",
      "sklearn 1.6.1\n",
      "torch 2.7.0+cpu\n",
      "cpu\n"
     ]
    }
   ],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T08:02:05.608427Z",
     "start_time": "2025-05-21T08:02:05.402775Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "# 转化成张量并且进行归一化\n",
    "transform = transforms.Compose([\n",
    "    ToTensor()\n",
    "])\n",
    "\n",
    "# train=true是加载训练集\n",
    "train_ds = datasets.FashionMNIST(root='../chapter_2_torch/data', train=True, transform=transform, download=True)\n",
    "\n",
    "#加载测试集\n",
    "test_ds = datasets.FashionMNIST(root='../chapter_2_torch/data', train=False, transform=transform, download=True)\n",
    "\n"
   ],
   "id": "5c603c32ba37869b",
   "outputs": [],
   "execution_count": 69
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**训练集，验证集，测试集，之所以要分出来验证集是因为深度学习的能力很强，在调整参数的过程其实就是泄露了数据，所以测试集现在用来在上线时测试模型的表现，就是一锤子买卖，不能再进行调整参数了**",
   "id": "ab386838c1a9d8aa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T08:02:05.624539Z",
     "start_time": "2025-05-21T08:02:05.608427Z"
    }
   },
   "cell_type": "code",
   "source": "type(train_ds)",
   "id": "29aec659db189100",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torchvision.datasets.mnist.FashionMNIST"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 70
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T08:02:05.636872Z",
     "start_time": "2025-05-21T08:02:05.626546Z"
    }
   },
   "cell_type": "code",
   "source": "len(train_ds)",
   "id": "ce6f36ebe735f75e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 71
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T08:02:05.649230Z",
     "start_time": "2025-05-21T08:02:05.640454Z"
    }
   },
   "cell_type": "code",
   "source": "train_ds.data.shape",
   "id": "db6ea2ec864b297c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 28, 28])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 72
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T08:02:05.660843Z",
     "start_time": "2025-05-21T08:02:05.649230Z"
    }
   },
   "cell_type": "code",
   "source": "type(train_ds.data)",
   "id": "81d33b0326105eb1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 73
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T08:02:05.729499Z",
     "start_time": "2025-05-21T08:02:05.660843Z"
    }
   },
   "cell_type": "code",
   "source": "print(train_ds.train_labels.unique())",
   "id": "2ea25242f1c70e6b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n"
     ]
    }
   ],
   "execution_count": 74
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T08:02:05.783512Z",
     "start_time": "2025-05-21T08:02:05.729499Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 通过id取数据，取到的是一个元祖,是第一个样本,在训练时，把特征和标签分开\n",
    "img, label = train_ds[0]\n",
    "img.shape\n",
    "# img.shape = (1, 28, 28)，这是因为通道数在最前面"
   ],
   "id": "6346b4cac875573e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 75
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T08:02:05.790050Z",
     "start_time": "2025-05-21T08:02:05.783512Z"
    }
   },
   "cell_type": "code",
   "source": "print(label)",
   "id": "a7f07b2590b5b00a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "execution_count": 76
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T08:02:05.798178Z",
     "start_time": "2025-05-21T08:02:05.790050Z"
    }
   },
   "cell_type": "code",
   "source": "type(img)",
   "id": "1ba8b6b5af70b0fe",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 77
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T08:02:05.845909Z",
     "start_time": "2025-05-21T08:02:05.798178Z"
    }
   },
   "cell_type": "code",
   "source": "img",
   "id": "eb61956a45878119",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000, 0.0510,\n",
       "          0.2863, 0.0000, 0.0000, 0.0039, 0.0157, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0039, 0.0039, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0000, 0.1412, 0.5333,\n",
       "          0.4980, 0.2431, 0.2118, 0.0000, 0.0000, 0.0000, 0.0039, 0.0118,\n",
       "          0.0157, 0.0000, 0.0000, 0.0118],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0235, 0.0000, 0.4000, 0.8000,\n",
       "          0.6902, 0.5255, 0.5647, 0.4824, 0.0902, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0471, 0.0392, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6078, 0.9255,\n",
       "          0.8118, 0.6980, 0.4196, 0.6118, 0.6314, 0.4275, 0.2510, 0.0902,\n",
       "          0.3020, 0.5098, 0.2824, 0.0588],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.2706, 0.8118, 0.8745,\n",
       "          0.8549, 0.8471, 0.8471, 0.6392, 0.4980, 0.4745, 0.4784, 0.5725,\n",
       "          0.5529, 0.3451, 0.6745, 0.2588],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0039, 0.0039, 0.0039, 0.0000, 0.7843, 0.9098, 0.9098,\n",
       "          0.9137, 0.8980, 0.8745, 0.8745, 0.8431, 0.8353, 0.6431, 0.4980,\n",
       "          0.4824, 0.7686, 0.8980, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7176, 0.8824, 0.8471,\n",
       "          0.8745, 0.8941, 0.9216, 0.8902, 0.8784, 0.8706, 0.8784, 0.8667,\n",
       "          0.8745, 0.9608, 0.6784, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7569, 0.8941, 0.8549,\n",
       "          0.8353, 0.7765, 0.7059, 0.8314, 0.8235, 0.8275, 0.8353, 0.8745,\n",
       "          0.8627, 0.9529, 0.7922, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0039, 0.0118, 0.0000, 0.0471, 0.8588, 0.8627, 0.8314,\n",
       "          0.8549, 0.7529, 0.6627, 0.8902, 0.8157, 0.8549, 0.8784, 0.8314,\n",
       "          0.8863, 0.7725, 0.8196, 0.2039],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0235, 0.0000, 0.3882, 0.9569, 0.8706, 0.8627,\n",
       "          0.8549, 0.7961, 0.7765, 0.8667, 0.8431, 0.8353, 0.8706, 0.8627,\n",
       "          0.9608, 0.4667, 0.6549, 0.2196],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0157, 0.0000, 0.0000, 0.2157, 0.9255, 0.8941, 0.9020,\n",
       "          0.8941, 0.9412, 0.9098, 0.8353, 0.8549, 0.8745, 0.9176, 0.8510,\n",
       "          0.8510, 0.8196, 0.3608, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0039, 0.0157, 0.0235, 0.0275, 0.0078, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.9294, 0.8863, 0.8510, 0.8745,\n",
       "          0.8706, 0.8588, 0.8706, 0.8667, 0.8471, 0.8745, 0.8980, 0.8431,\n",
       "          0.8549, 1.0000, 0.3020, 0.0000],\n",
       "         [0.0000, 0.0118, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.2431, 0.5686, 0.8000, 0.8941, 0.8118, 0.8353, 0.8667,\n",
       "          0.8549, 0.8157, 0.8275, 0.8549, 0.8784, 0.8745, 0.8588, 0.8431,\n",
       "          0.8784, 0.9569, 0.6235, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.1725, 0.3216, 0.4196,\n",
       "          0.7412, 0.8941, 0.8627, 0.8706, 0.8510, 0.8863, 0.7843, 0.8039,\n",
       "          0.8275, 0.9020, 0.8784, 0.9176, 0.6902, 0.7373, 0.9804, 0.9725,\n",
       "          0.9137, 0.9333, 0.8431, 0.0000],\n",
       "         [0.0000, 0.2235, 0.7333, 0.8157, 0.8784, 0.8667, 0.8784, 0.8157,\n",
       "          0.8000, 0.8392, 0.8157, 0.8196, 0.7843, 0.6235, 0.9608, 0.7569,\n",
       "          0.8078, 0.8745, 1.0000, 1.0000, 0.8667, 0.9176, 0.8667, 0.8275,\n",
       "          0.8627, 0.9098, 0.9647, 0.0000],\n",
       "         [0.0118, 0.7922, 0.8941, 0.8784, 0.8667, 0.8275, 0.8275, 0.8392,\n",
       "          0.8039, 0.8039, 0.8039, 0.8627, 0.9412, 0.3137, 0.5882, 1.0000,\n",
       "          0.8980, 0.8667, 0.7373, 0.6039, 0.7490, 0.8235, 0.8000, 0.8196,\n",
       "          0.8706, 0.8941, 0.8824, 0.0000],\n",
       "         [0.3843, 0.9137, 0.7765, 0.8235, 0.8706, 0.8980, 0.8980, 0.9176,\n",
       "          0.9765, 0.8627, 0.7608, 0.8431, 0.8510, 0.9451, 0.2549, 0.2863,\n",
       "          0.4157, 0.4588, 0.6588, 0.8588, 0.8667, 0.8431, 0.8510, 0.8745,\n",
       "          0.8745, 0.8784, 0.8980, 0.1137],\n",
       "         [0.2941, 0.8000, 0.8314, 0.8000, 0.7569, 0.8039, 0.8275, 0.8824,\n",
       "          0.8471, 0.7255, 0.7725, 0.8078, 0.7765, 0.8353, 0.9412, 0.7647,\n",
       "          0.8902, 0.9608, 0.9373, 0.8745, 0.8549, 0.8314, 0.8196, 0.8706,\n",
       "          0.8627, 0.8667, 0.9020, 0.2627],\n",
       "         [0.1882, 0.7961, 0.7176, 0.7608, 0.8353, 0.7725, 0.7255, 0.7451,\n",
       "          0.7608, 0.7529, 0.7922, 0.8392, 0.8588, 0.8667, 0.8627, 0.9255,\n",
       "          0.8824, 0.8471, 0.7804, 0.8078, 0.7294, 0.7098, 0.6941, 0.6745,\n",
       "          0.7098, 0.8039, 0.8078, 0.4510],\n",
       "         [0.0000, 0.4784, 0.8588, 0.7569, 0.7020, 0.6706, 0.7176, 0.7686,\n",
       "          0.8000, 0.8235, 0.8353, 0.8118, 0.8275, 0.8235, 0.7843, 0.7686,\n",
       "          0.7608, 0.7490, 0.7647, 0.7490, 0.7765, 0.7529, 0.6902, 0.6118,\n",
       "          0.6549, 0.6941, 0.8235, 0.3608],\n",
       "         [0.0000, 0.0000, 0.2902, 0.7412, 0.8314, 0.7490, 0.6863, 0.6745,\n",
       "          0.6863, 0.7098, 0.7255, 0.7373, 0.7412, 0.7373, 0.7569, 0.7765,\n",
       "          0.8000, 0.8196, 0.8235, 0.8235, 0.8275, 0.7373, 0.7373, 0.7608,\n",
       "          0.7529, 0.8471, 0.6667, 0.0000],\n",
       "         [0.0078, 0.0000, 0.0000, 0.0000, 0.2588, 0.7843, 0.8706, 0.9294,\n",
       "          0.9373, 0.9490, 0.9647, 0.9529, 0.9569, 0.8667, 0.8627, 0.7569,\n",
       "          0.7490, 0.7020, 0.7137, 0.7137, 0.7098, 0.6902, 0.6510, 0.6588,\n",
       "          0.3882, 0.2275, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1569,\n",
       "          0.2392, 0.1725, 0.2824, 0.1608, 0.1373, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000]]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 78
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T08:02:05.859449Z",
     "start_time": "2025-05-21T08:02:05.846926Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 显示图片，这里需要把transforms.ToTensor(),进行归一化注释掉，否则是不行的\n",
    "def show_img_content(img):\n",
    "    from PIL import Image\n",
    "\n",
    "    # 打开一个图像文件\n",
    "    # img = Image.open(img)\n",
    "\n",
    "    print(\"图像大小:\", img.size)\n",
    "    print(\"图像模式:\", img.mode)\n",
    "\n",
    "    # 如果图像是单通道的，比如灰度图，你可以这样获取像素值列表：\n",
    "    if img.mode == 'L':\n",
    "        pixel_values = list(img.getdata())\n",
    "        print(pixel_values)\n",
    "\n",
    "\n",
    "show_img_content(img)  #这里必须把上面的 transforms.ToTensor(), # 转换为tensor，进行归一化注释掉，否则是不行的"
   ],
   "id": "112fd931f822057c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "图像大小: <built-in method size of Tensor object at 0x000002798382E170>\n",
      "图像模式: <built-in method mode of Tensor object at 0x000002798382E170>\n"
     ]
    }
   ],
   "execution_count": 79
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T08:02:06.645792Z",
     "start_time": "2025-05-21T08:02:05.860456Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#这个代码必须是注释了上面的 transforms.ToTensor()才能够运行的\n",
    "def show_single_image(img_arr):\n",
    "    plt.imshow(img_arr, cmap=\"binary\")  # 显示图片\n",
    "    plt.colorbar()  # 显示颜色条\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "show_single_image(img)"
   ],
   "id": "c034ec3b949d9e1c",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Invalid shape (1, 28, 28) for image data",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mTypeError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[80]\u001B[39m\u001B[32m, line 8\u001B[39m\n\u001B[32m      4\u001B[39m     plt.colorbar()  \u001B[38;5;66;03m# 显示颜色条\u001B[39;00m\n\u001B[32m      5\u001B[39m     plt.show()\n\u001B[32m----> \u001B[39m\u001B[32m8\u001B[39m \u001B[43mshow_single_image\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[80]\u001B[39m\u001B[32m, line 3\u001B[39m, in \u001B[36mshow_single_image\u001B[39m\u001B[34m(img_arr)\u001B[39m\n\u001B[32m      2\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mshow_single_image\u001B[39m(img_arr):\n\u001B[32m----> \u001B[39m\u001B[32m3\u001B[39m     \u001B[43mplt\u001B[49m\u001B[43m.\u001B[49m\u001B[43mimshow\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg_arr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcmap\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mbinary\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# 显示图片\u001B[39;00m\n\u001B[32m      4\u001B[39m     plt.colorbar()  \u001B[38;5;66;03m# 显示颜色条\u001B[39;00m\n\u001B[32m      5\u001B[39m     plt.show()\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Python312\\Lib\\site-packages\\matplotlib\\pyplot.py:3590\u001B[39m, in \u001B[36mimshow\u001B[39m\u001B[34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, colorizer, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, data, **kwargs)\u001B[39m\n\u001B[32m   3568\u001B[39m \u001B[38;5;129m@_copy_docstring_and_deprecators\u001B[39m(Axes.imshow)\n\u001B[32m   3569\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mimshow\u001B[39m(\n\u001B[32m   3570\u001B[39m     X: ArrayLike | PIL.Image.Image,\n\u001B[32m   (...)\u001B[39m\u001B[32m   3588\u001B[39m     **kwargs,\n\u001B[32m   3589\u001B[39m ) -> AxesImage:\n\u001B[32m-> \u001B[39m\u001B[32m3590\u001B[39m     __ret = \u001B[43mgca\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mimshow\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   3591\u001B[39m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3592\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcmap\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcmap\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3593\u001B[39m \u001B[43m        \u001B[49m\u001B[43mnorm\u001B[49m\u001B[43m=\u001B[49m\u001B[43mnorm\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3594\u001B[39m \u001B[43m        \u001B[49m\u001B[43maspect\u001B[49m\u001B[43m=\u001B[49m\u001B[43maspect\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3595\u001B[39m \u001B[43m        \u001B[49m\u001B[43minterpolation\u001B[49m\u001B[43m=\u001B[49m\u001B[43minterpolation\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3596\u001B[39m \u001B[43m        \u001B[49m\u001B[43malpha\u001B[49m\u001B[43m=\u001B[49m\u001B[43malpha\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3597\u001B[39m \u001B[43m        \u001B[49m\u001B[43mvmin\u001B[49m\u001B[43m=\u001B[49m\u001B[43mvmin\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3598\u001B[39m \u001B[43m        \u001B[49m\u001B[43mvmax\u001B[49m\u001B[43m=\u001B[49m\u001B[43mvmax\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3599\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcolorizer\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcolorizer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3600\u001B[39m \u001B[43m        \u001B[49m\u001B[43morigin\u001B[49m\u001B[43m=\u001B[49m\u001B[43morigin\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3601\u001B[39m \u001B[43m        \u001B[49m\u001B[43mextent\u001B[49m\u001B[43m=\u001B[49m\u001B[43mextent\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3602\u001B[39m \u001B[43m        \u001B[49m\u001B[43minterpolation_stage\u001B[49m\u001B[43m=\u001B[49m\u001B[43minterpolation_stage\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3603\u001B[39m \u001B[43m        \u001B[49m\u001B[43mfilternorm\u001B[49m\u001B[43m=\u001B[49m\u001B[43mfilternorm\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3604\u001B[39m \u001B[43m        \u001B[49m\u001B[43mfilterrad\u001B[49m\u001B[43m=\u001B[49m\u001B[43mfilterrad\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3605\u001B[39m \u001B[43m        \u001B[49m\u001B[43mresample\u001B[49m\u001B[43m=\u001B[49m\u001B[43mresample\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3606\u001B[39m \u001B[43m        \u001B[49m\u001B[43murl\u001B[49m\u001B[43m=\u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3607\u001B[39m \u001B[43m        \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43m(\u001B[49m\u001B[43m{\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mdata\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m}\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3608\u001B[39m \u001B[43m        \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3609\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   3610\u001B[39m     sci(__ret)\n\u001B[32m   3611\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m __ret\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Python312\\Lib\\site-packages\\matplotlib\\__init__.py:1521\u001B[39m, in \u001B[36m_preprocess_data.<locals>.inner\u001B[39m\u001B[34m(ax, data, *args, **kwargs)\u001B[39m\n\u001B[32m   1518\u001B[39m \u001B[38;5;129m@functools\u001B[39m.wraps(func)\n\u001B[32m   1519\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34minner\u001B[39m(ax, *args, data=\u001B[38;5;28;01mNone\u001B[39;00m, **kwargs):\n\u001B[32m   1520\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m data \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1521\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1522\u001B[39m \u001B[43m            \u001B[49m\u001B[43max\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1523\u001B[39m \u001B[43m            \u001B[49m\u001B[43m*\u001B[49m\u001B[38;5;28;43mmap\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcbook\u001B[49m\u001B[43m.\u001B[49m\u001B[43msanitize_sequence\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1524\u001B[39m \u001B[43m            \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43m{\u001B[49m\u001B[43mk\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mcbook\u001B[49m\u001B[43m.\u001B[49m\u001B[43msanitize_sequence\u001B[49m\u001B[43m(\u001B[49m\u001B[43mv\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mk\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mv\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m.\u001B[49m\u001B[43mitems\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1526\u001B[39m     bound = new_sig.bind(ax, *args, **kwargs)\n\u001B[32m   1527\u001B[39m     auto_label = (bound.arguments.get(label_namer)\n\u001B[32m   1528\u001B[39m                   \u001B[38;5;129;01mor\u001B[39;00m bound.kwargs.get(label_namer))\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Python312\\Lib\\site-packages\\matplotlib\\axes\\_axes.py:5976\u001B[39m, in \u001B[36mAxes.imshow\u001B[39m\u001B[34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, colorizer, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs)\u001B[39m\n\u001B[32m   5973\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m aspect \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m   5974\u001B[39m     \u001B[38;5;28mself\u001B[39m.set_aspect(aspect)\n\u001B[32m-> \u001B[39m\u001B[32m5976\u001B[39m \u001B[43mim\u001B[49m\u001B[43m.\u001B[49m\u001B[43mset_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   5977\u001B[39m im.set_alpha(alpha)\n\u001B[32m   5978\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m im.get_clip_path() \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m   5979\u001B[39m     \u001B[38;5;66;03m# image does not already have clipping set, clip to Axes patch\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Python312\\Lib\\site-packages\\matplotlib\\image.py:685\u001B[39m, in \u001B[36m_ImageBase.set_data\u001B[39m\u001B[34m(self, A)\u001B[39m\n\u001B[32m    683\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(A, PIL.Image.Image):\n\u001B[32m    684\u001B[39m     A = pil_to_array(A)  \u001B[38;5;66;03m# Needed e.g. to apply png palette.\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m685\u001B[39m \u001B[38;5;28mself\u001B[39m._A = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_normalize_image_array\u001B[49m\u001B[43m(\u001B[49m\u001B[43mA\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    686\u001B[39m \u001B[38;5;28mself\u001B[39m._imcache = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    687\u001B[39m \u001B[38;5;28mself\u001B[39m.stale = \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Python312\\Lib\\site-packages\\matplotlib\\image.py:653\u001B[39m, in \u001B[36m_ImageBase._normalize_image_array\u001B[39m\u001B[34m(A)\u001B[39m\n\u001B[32m    651\u001B[39m     A = A.squeeze(-\u001B[32m1\u001B[39m)  \u001B[38;5;66;03m# If just (M, N, 1), assume scalar and apply colormap.\u001B[39;00m\n\u001B[32m    652\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (A.ndim == \u001B[32m2\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m A.ndim == \u001B[32m3\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m A.shape[-\u001B[32m1\u001B[39m] \u001B[38;5;129;01min\u001B[39;00m [\u001B[32m3\u001B[39m, \u001B[32m4\u001B[39m]):\n\u001B[32m--> \u001B[39m\u001B[32m653\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mInvalid shape \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mA.shape\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m for image data\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m    654\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m A.ndim == \u001B[32m3\u001B[39m:\n\u001B[32m    655\u001B[39m     \u001B[38;5;66;03m# If the input data has values outside the valid range (after\u001B[39;00m\n\u001B[32m    656\u001B[39m     \u001B[38;5;66;03m# normalisation), we issue a warning and then clip X to the bounds\u001B[39;00m\n\u001B[32m    657\u001B[39m     \u001B[38;5;66;03m# - otherwise casting wraps extreme values, hiding outliers and\u001B[39;00m\n\u001B[32m    658\u001B[39m     \u001B[38;5;66;03m# making reliable interpretation impossible.\u001B[39;00m\n\u001B[32m    659\u001B[39m     high = \u001B[32m255\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m np.issubdtype(A.dtype, np.integer) \u001B[38;5;28;01melse\u001B[39;00m \u001B[32m1\u001B[39m\n",
      "\u001B[31mTypeError\u001B[39m: Invalid shape (1, 28, 28) for image data"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 80
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def show_imgs(n_rows, n_cols, train_ds, class_names):\n",
    "    assert n_rows * n_cols < len(train_ds)  #确保打印的图片小于总样本数\n",
    "    plt.figure(figsize = (n_cols * 1.4, n_rows * 1.6))  #宽1.4高1.6，宽，高\n",
    "    for row in range(n_rows):\n",
    "        for col in range(n_cols):\n",
    "            index = n_cols * row + col  # 计算索引，从0开始\n",
    "            plt.subplot(n_rows, n_cols, index+1)#因为从1开始\n",
    "            img, label = train_ds[index]\n",
    "            img = np.transpose(img, (1, 2, 0))  # 通道换到最后一维\n",
    "            print(img.shape)\n",
    "            plt.imshow(img, cmap=\"binary\",\n",
    "                       interpolation = 'nearest')#interpolation='nearest'是临近插值\n",
    "            plt.axis('off')#去除坐标系\n",
    "            plt.title(class_names[label]) # 显示类别名称\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "\n",
    "#已知的图片类别\n",
    "# lables在这个路径https://github.com/zalandoresearch/fashion-mnist\n",
    "class_names = ['T-shirt', 'Trouser', 'Pullover', 'Dress',\n",
    "               'Coat', 'Sandal', 'Shirt', 'Sneaker',\n",
    "               'Bag', 'Ankle boot'] #0-9分别代表的类别\n",
    "#只是打印了前15个样本\n",
    "show_imgs(3, 5, train_ds, class_names)\n"
   ],
   "id": "8143b076afc5f8d9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 从数据集到dataloader\n",
    "train_loader = torch.utils.data.DataLoader(train_ds, batch_size=32, shuffle=True) #batch_size分批，shuffle洗牌\n",
    "val_loader = torch.utils.data.DataLoader(test_ds, batch_size=32, shuffle=False)"
   ],
   "id": "d034234757dadf39",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "在`PyTorch`中，`DataLoader`是一个迭代器，它封装了数据的加载和预处理过程，使得在训练机器学习模型时可以方便地批量加载数据。`DataLoader`主要负责以下几个方面：\n",
    "\n",
    "1. **批量加载数据**：`DataLoader`可以将数据集（Dataset）切分为更小的批次（batch），每次迭代提供一小批量数据，而不是单个数据点。这有助于模型学习数据中的统计依赖性，并且可以更高效地利用GPU等硬件的并行计算能力。\n",
    "\n",
    "2. **数据打乱**：默认情况下，`DataLoader`会在每个epoch（训练周期）开始时打乱数据的顺序。这有助于模型训练时避免陷入局部最优解，并且可以提高模型的泛化能力。\n",
    "\n",
    "3. **多线程数据加载**：`DataLoader`支持多线程（通过参数`num_workers`）来并行地加载数据，这可以显著减少训练过程中的等待时间，尤其是在处理大规模数据集时。\n",
    "\n",
    "4. **数据预处理**：`DataLoader`可以与`transforms`结合使用，对加载的数据进行预处理，如归一化、标准化、数据增强等操作。\n",
    "\n",
    "5. **内存管理**：`DataLoader`负责管理数据的内存使用，确保在训练过程中不会耗尽内存资源。\n",
    "\n",
    "6. **易用性**：`DataLoader`提供了一个简单的接口，可以很容易地集成到训练循环中。\n",
    "\n"
   ],
   "id": "d63f82d27cbea866"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 定义模型",
   "id": "81967158cafa460d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__() # 继承父类的初始化方法，子类有父类的属性\n",
    "        self.flatten = nn.Flatten()\n",
    "        # 将一张图片展平\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(784, 300),\n",
    "            nn.ReLU(),# 激活函数，如果x > 0 则为x， 否则为0\n",
    "            nn.Linear(300, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 10),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "model = NeuralNetwork()"
   ],
   "id": "16c6759dc4a84c3c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model",
   "id": "6f351271a3bf4f33",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(name, param.shape)"
   ],
   "id": "cbe070a6d485e85c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 看看模型参数\n",
    "list(model.parameters())  # 这种方法拿到模型的所有可学习参数,"
   ],
   "id": "bf57e9d5cb7914e0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "96531b9c3fecca4f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 训练\n",
    "pytorch的训练需要自行实现，包括\n",
    "1. 定义损失函数\n",
    "2. 定义优化器\n",
    "3. 定义训练步\n",
    "4. 训练"
   ],
   "id": "2eefe5de7885163"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T08:06:16.466856Z",
     "start_time": "2025-05-21T08:06:16.432744Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 定义损失函数\n",
    "loss_fct = nn.CrossEntropyLoss() # 内部先做了softmax，然后计算交叉熵\n",
    "# 定义优化器，采用SGD\n",
    "# 随机梯度下降\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n"
   ],
   "id": "cf0d59f3fa85128a",
   "outputs": [],
   "execution_count": 81
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T09:14:08.697518Z",
     "start_time": "2025-05-21T09:14:08.395176Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 临时禁用梯度计算节省内存加速计算\n",
    "@torch.no_grad()\n",
    "def evaluating(model, data_loader, loss_fct):\n",
    "    loss_list = [] # 记录损失\n",
    "    pred_list = [] # 记录预测\n",
    "    label_list = [] # 记录标签\n",
    "    for datas, labels in data_loader:\n",
    "        datas = datas.to(device) # 转到GPU\n",
    "        labels = labels.to(device)\n",
    "        # 前向计算\n",
    "        logits = model(datas)\n",
    "        loss = loss_fct(logits, labels)\n",
    "        loss_list.append(loss.item())\n",
    "        # 验证集预测返回最大值的索引\n",
    "        pred = logits.argmax(axis=-1)\n",
    "        pred_list.extend(pred.cpu().numpy().tolist())\n",
    "        label_list.extend(labels.cpu().numpy().tolist())\n",
    "    # 计算准确率\n",
    "    acc = accuracy_score(label_list, pred_list)\n",
    "    return np.mean(loss_list), acc"
   ],
   "id": "dd7a2240c05d107",
   "outputs": [],
   "execution_count": 85
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 训练",
   "id": "b6606838290831d1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T09:18:57.782259Z",
     "start_time": "2025-05-21T09:14:11.002774Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def training(model, train_loader, val_loader, epoch, loss_fct,optimizer, eval_step):\n",
    "    record_dict = {\n",
    "        \"train\":[],\n",
    "        \"val\": []\n",
    "    }\n",
    "    global_step = 0\n",
    "    model.train()\n",
    "    with tqdm(total=epoch * len(train_loader)) as pbar:\n",
    "        for epoch_id in range(epoch): # 训练epoch次\n",
    "            # training\n",
    "            for datas, labels in train_loader: #执行次数是60000/32=1875\n",
    "                datas = datas.to(device) #datas尺寸是[batch_size,1,28,28]\n",
    "                labels = labels.to(device) #labels尺寸是[batch_size]\n",
    "                # 梯度清空\n",
    "                optimizer.zero_grad()\n",
    "                # 模型前向计算\n",
    "                logits = model(datas)\n",
    "                # 计算损失\n",
    "                loss = loss_fct(logits, labels)\n",
    "                # 梯度回传，loss.backward()会计算梯度，loss对模型参数求导\n",
    "                loss.backward()\n",
    "                # 调整优化器，包括学习率的变动等,优化器的学习率会随着训练的进行而减小，更新w,b\n",
    "                optimizer.step() #梯度是计算并存储在模型参数的 .grad 属性中，优化器使用这些存储的梯度来更新模型参数\n",
    "\n",
    "                preds = logits.argmax(axis=-1) # 训练集预测\n",
    "                acc = accuracy_score(labels.cpu().numpy(), preds.cpu().numpy())   # 计算准确率，numpy可以\n",
    "                loss = loss.cpu().item() # 损失转到CPU，item()取值,一个数值\n",
    "                # record\n",
    "                \n",
    "                record_dict[\"train\"].append({\n",
    "                    \"loss\": loss, \"acc\": acc, \"step\": global_step\n",
    "                }) # 记录训练集信息，每一步的损失，准确率，步数\n",
    "                \n",
    "                # evaluating\n",
    "                if global_step % eval_step == 0:\n",
    "                    model.eval() # 进入评估模式\n",
    "                    val_loss, val_acc = evaluating(model, val_loader, loss_fct)\n",
    "                    record_dict[\"val\"].append({\n",
    "                        \"loss\": val_loss, \"acc\": val_acc, \"step\": global_step\n",
    "                    })\n",
    "                    model.train() # 进入训练模式\n",
    "\n",
    "                # udate step\n",
    "                global_step += 1 # 全局步数加1\n",
    "                pbar.update(1) # 更新进度条\n",
    "                pbar.set_postfix({\"epoch\": epoch_id}) # 设置进度条显示信息\n",
    "        \n",
    "    return record_dict\n",
    "        \n",
    "\n",
    "epoch = 20 #改为40\n",
    "model = model.to(device)\n",
    "record = training(model, train_loader, val_loader, epoch, loss_fct, optimizer, eval_step=1000)"
   ],
   "id": "2be552536d5af5ac",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/37500 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bd10fc757850489db29d3a390ffe39b8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 86
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T09:19:03.491064Z",
     "start_time": "2025-05-21T09:19:03.482358Z"
    }
   },
   "cell_type": "code",
   "source": "record[\"train\"][-5:]",
   "id": "8f322787cff7d73c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'loss': 0.20618127286434174, 'acc': 0.90625, 'step': 37495},\n",
       " {'loss': 0.4165700376033783, 'acc': 0.8125, 'step': 37496},\n",
       " {'loss': 0.33572226762771606, 'acc': 0.84375, 'step': 37497},\n",
       " {'loss': 0.2562563419342041, 'acc': 0.9375, 'step': 37498},\n",
       " {'loss': 0.2960897386074066, 'acc': 0.90625, 'step': 37499}]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 87
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T09:19:23.130969Z",
     "start_time": "2025-05-21T09:19:23.119229Z"
    }
   },
   "cell_type": "code",
   "source": "record[\"val\"][-5:]",
   "id": "5fa395d313cbe494",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'loss': np.float64(0.3648016456121835), 'acc': 0.8668, 'step': 33000},\n",
       " {'loss': np.float64(0.3572585197588125), 'acc': 0.8701, 'step': 34000},\n",
       " {'loss': np.float64(0.3582308352374421), 'acc': 0.8701, 'step': 35000},\n",
       " {'loss': np.float64(0.36725849999834936), 'acc': 0.8688, 'step': 36000},\n",
       " {'loss': np.float64(0.3550871053038123), 'acc': 0.8709, 'step': 37000}]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 88
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T09:24:17.195160Z",
     "start_time": "2025-05-21T09:24:17.189143Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "a0d3d433fc72bf1f",
   "outputs": [],
   "execution_count": 94
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "49117f6c52f667fb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
